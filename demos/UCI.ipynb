{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains an example of using the given DVIP implementation over the considered UCI datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook reload options\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global Imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "# Local Imports\n",
    "sys.path.append(\"..\")\n",
    "from src.dvip import DVIP_Base\n",
    "from src.likelihood import Gaussian\n",
    "from src.generative_functions import SimplerBayesLinear\n",
    "from src.layers_init import init_layers\n",
    "from utils.dataset import Boston_Dataset\n",
    "from utils.metrics import MetricsRegression\n",
    "from utils.pytorch_learning import fit, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theese are the parameters that determine the experiments. Most of these values are set to their default value. Please refer to `utils/process_flass.py` to know more about each parameter. Remarkably:\n",
    "\n",
    "- `vip_layers`: must be specified in a vector. An unique integer corresponds to the given number of layers all of them with the data dimension as width. In order to specify the width of each layer, the vector is used. I.e, [30, 10, 1] means the first layer contains 30 units, the second 10 and the last 1 (must match the target dimensionality).\n",
    "- `bnn_structure`: Specifies the width of the inner layers of the prior BNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"vip_layers\": [1],\n",
    "        \"genf\": \"BNN\",\n",
    "        \"regression_coeffs\": 20,\n",
    "        \"bnn_structure\": [10, 10],\n",
    "        \"bnn_inner_dim\": 100,\n",
    "        \"bnn_layer\": SimplerBayesLinear,\n",
    "        \"activation\": torch.tanh,\n",
    "        \"device\": \"cpu\",\n",
    "        \"dtype\": torch.float64,\n",
    "        \"seed\": 2147483647,\n",
    "        \"fix_prior_noise\": True,\n",
    "        \"genf_full_output\": False,\n",
    "        \"final_layer_mu\": 0,\n",
    "        \"inner_layers_mu\": 0,\n",
    "        \"final_layer_sqrt\": 1,\n",
    "        \"inner_layers_sqrt\": 1e-5,\n",
    "        \"inner_layers_noise\": -5,\n",
    "        \"final_layer_noise\": None,\n",
    "        \"dropout\": 0.0,\n",
    "        \"prior_kl\": False,\n",
    "        \"zero_mean_prior\": False,\n",
    "        \"input_prop\": True,\n",
    "        \"bb_alpha\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed for reproductibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(params[\"seed\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset and desired split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  455\n",
      "Input dimension:  13\n",
      "Label dimension:  1\n",
      "Labels mean value:  [[22.51604396]]\n",
      "Labels standard deviation:  [[9.23007422]]\n"
     ]
    }
   ],
   "source": [
    "dataset = Boston_Dataset()\n",
    "split = 0\n",
    "train_dataset, train_test_dataset, test_dataset = dataset.get_split(test_size = 0.1, \n",
    "                                                                    seed = params[\"seed\"] + split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data loaders for training and test partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "train_test_loader = DataLoader(train_test_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: 13->1 MF: None\n"
     ]
    }
   ],
   "source": [
    "layers = init_layers(train_dataset.inputs, dataset.output_dim, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = Gaussian(dtype = params[\"dtype\"], device = params[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define DVIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvip = DVIP_Base(\n",
    "    likelihood,\n",
    "    layers,\n",
    "    len(train_dataset),\n",
    "    bb_alpha=params[\"bb_alpha\"],\n",
    "    num_samples=1,\n",
    "    y_mean=train_dataset.targets_mean,\n",
    "    y_std=train_dataset.targets_std,\n",
    "    dtype=params[\"dtype\"],\n",
    "    device=params[\"device\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|██████████| 150000/150000 [13:57<00:00, 179.08 iteration/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define optimizer and compile model\n",
    "opt = torch.optim.Adam(dvip.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "fit(\n",
    "    dvip,\n",
    "    train_loader,\n",
    "    opt,\n",
    "    use_tqdm=True,\n",
    "    return_loss=False,\n",
    "    iterations=150_000,\n",
    "    device=params[\"device\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute test metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating : 100%|██████████| 5/5 [00:01<00:00,  4.36iteration/s]\n",
      "Evaluating : 100%|██████████| 1/1 [00:00<00:00,  7.99iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS: \n",
      "\t - LOSS: 86.90116882324219\n",
      "\t - RMSE: 5.8104681968688965\n",
      "\t - NLL: 2.8939199447631836\n",
      "\t - CRPS: 2.52249813079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = MetricsRegression\n",
    "\n",
    "# Set the number of test samples to generate\n",
    "dvip.num_samples = 100\n",
    "\n",
    "# Test the model\n",
    "train_metrics = score(dvip, train_test_loader, MetricsRegression, use_tqdm = True, device=params[\"device\"])\n",
    "test_metrics = score(dvip, test_loader, MetricsRegression, use_tqdm=True, device=params[\"device\"])\n",
    "\n",
    "print(\"TEST RESULTS: \")\n",
    "for k, v in test_metrics.items():\n",
    "    print(\"\\t - {}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b281a6f164d6590c4139759792e3875171ae0f0d6d12fad8f07687152bcc70be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
