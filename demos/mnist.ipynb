{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.dvip import DVIP_Base\n",
    "from src.layers import VIPLayer\n",
    "from src.likelihood import Gaussian\n",
    "from src.generative_functions import BayesianConvNN, BayesianNN, BayesLinear\n",
    "from src.likelihood import BroadcastedLikelihood, MultiClass\n",
    "from utils.dataset import Test_Dataset, Training_Dataset, MNIST_Dataset\n",
    "from utils.metrics import MetricsRegression, MetricsClassification\n",
    "from utils.process_flags import manage_experiment_configuration\n",
    "from utils.pytorch_learning import fit, fit_with_metrics, score\n",
    "from scripts.filename import create_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  60000\n",
      "Input dimension:  784\n",
      "Label dimension:  1\n",
      "Labels mean value:  0\n",
      "Labels standard deviation:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnist = MNIST_Dataset()\n",
    "train_dataset, train_test_dataset, test_dataset = mnist.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "train_test_loader = DataLoader(train_test_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_f = BayesianConvNN(num_samples = 20, input_dim=(28, 28), output_dim = 1, activation = torch.nn.functional.relu)\n",
    "layer = VIPLayer(gen_f, 20, 28*28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_f2 = BayesianNN([], num_samples = 20, input_dim=25, output_dim = 10, activation = torch.nn.functional.relu, layer_model=BayesLinear)\n",
    "layer2 = VIPLayer(gen_f2, 20, 25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvip = DVIP_Base(\n",
    "    BroadcastedLikelihood(MultiClass(10, torch.float64, \"cpu\")),\n",
    "    [layer],\n",
    "    len(train_dataset),\n",
    "    bb_alpha=0.0,\n",
    "    num_samples=1,\n",
    "    dtype=torch.float64,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- MODEL PARAMETERS ----\n",
      " VIP_LAYERS\n",
      "\t 0\n",
      "\t\t q_mu\n",
      "\t\t\t torch.Size([20, 1])\n",
      "\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t q_sqrt_tri\n",
      "\t\t\t torch.Size([210, 1])\n",
      "\t\t\t [1. 0. ... 0. 1.]\n",
      "\t\t GENERATIVE_FUNCTION\n",
      "\t\t\t CONV1\n",
      "\t\t\t\t W_mu\n",
      "\t\t\t\t\t torch.Size([3, 3])\n",
      "\t\t\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t\t\t W_log_std\n",
      "\t\t\t\t\t torch.Size([3, 3])\n",
      "\t\t\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t\t\t bias_mu\n",
      "\t\t\t\t\t torch.Size([1])\n",
      "\t\t\t\t\t [0.]\n",
      "\t\t\t\t bias_log_std\n",
      "\t\t\t\t\t torch.Size([1])\n",
      "\t\t\t\t\t [0.]\n",
      "\t\t\t CONV2\n",
      "\t\t\t\t W_mu\n",
      "\t\t\t\t\t torch.Size([3, 3])\n",
      "\t\t\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t\t\t W_log_std\n",
      "\t\t\t\t\t torch.Size([3, 3])\n",
      "\t\t\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t\t\t bias_mu\n",
      "\t\t\t\t\t torch.Size([1])\n",
      "\t\t\t\t\t [0.]\n",
      "\t\t\t\t bias_log_std\n",
      "\t\t\t\t\t torch.Size([1])\n",
      "\t\t\t\t\t [0.]\n",
      "\t\t\t CONV3\n",
      "\t\t\t\t W_mu\n",
      "\t\t\t\t\t torch.Size([5, 5])\n",
      "\t\t\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t\t\t W_log_std\n",
      "\t\t\t\t\t torch.Size([5, 5])\n",
      "\t\t\t\t\t [0. 0. ... 0. 0.]\n",
      "\t\t\t\t bias_mu\n",
      "\t\t\t\t\t torch.Size([1])\n",
      "\t\t\t\t\t [0.]\n",
      "\t\t\t\t bias_log_std\n",
      "\t\t\t\t\t torch.Size([1])\n",
      "\t\t\t\t\t [0.]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dvip.print_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training : 100%|██████████| 20/20 [17:40<00:00, 53.01s/epoch, loss_train=2.73e+5, nll_train=0.694, acc_train=0.0987]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m metrics \u001b[39m=\u001b[39m MetricsClassification\n\u001b[0;32m      4\u001b[0m \u001b[39m# Perform training\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_hist, val_hist \u001b[39m=\u001b[39m fit_with_metrics(\n\u001b[0;32m      6\u001b[0m     dvip,\n\u001b[0;32m      7\u001b[0m     train_loader,\n\u001b[0;32m      8\u001b[0m     opt,\n\u001b[0;32m      9\u001b[0m     metrics,\n\u001b[0;32m     10\u001b[0m     \u001b[39m#val_generator=test_loader,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[0;32m     12\u001b[0m     device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(dvip.parameters(), lr=0.01)\n",
    "metrics = MetricsClassification\n",
    "\n",
    "# Perform training\n",
    "train_hist, val_hist = fit_with_metrics(\n",
    "    dvip,\n",
    "    train_loader,\n",
    "    opt,\n",
    "    metrics,\n",
    "    #val_generator=test_loader,\n",
    "    epochs=20,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'LOSS': 17164.55078125,\n",
       "  'NLL': 5.4976372718811035,\n",
       "  'ACC': 0.10589999705553055},\n",
       " {'LOSS': 15817.701171875,\n",
       "  'NLL': 5.999475002288818,\n",
       "  'ACC': 0.10289999842643738},\n",
       " {'LOSS': 15536.6572265625,\n",
       "  'NLL': 6.026484489440918,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15454.3740234375,\n",
       "  'NLL': 6.040866374969482,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15414.98828125,\n",
       "  'NLL': 5.9806599617004395,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15377.451171875,\n",
       "  'NLL': 5.988156318664551,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15356.697265625,\n",
       "  'NLL': 5.973512172698975,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15362.892578125,\n",
       "  'NLL': 5.985396385192871,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15326.65625, 'NLL': 5.955053806304932, 'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15322.0498046875,\n",
       "  'NLL': 5.951890468597412,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15309.2421875, 'NLL': 5.927739143371582, 'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15304.8984375, 'NLL': 5.935015678405762, 'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15294.501953125,\n",
       "  'NLL': 5.931366443634033,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15299.619140625,\n",
       "  'NLL': 5.933835983276367,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15273.5263671875,\n",
       "  'NLL': 5.9284281730651855,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15276.6044921875,\n",
       "  'NLL': 5.923060894012451,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15261.849609375,\n",
       "  'NLL': 5.908437252044678,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15246.279296875,\n",
       "  'NLL': 5.921513080596924,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15207.755859375,\n",
       "  'NLL': 5.912977695465088,\n",
       "  'ACC': 0.10279999673366547},\n",
       " {'LOSS': 15187.0546875, 'NLL': 5.906867504119873, 'ACC': 0.10279999673366547}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d22d6b27a92cd994f9e31f4a97960133434df2a462e6e0a555d37d81245812e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
